{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Portable CPU Benchmark (No Big Downloads)\n",
        "\n",
        "本 notebook 旨在 **“即插即用”** 地在任意 CPU 设备上快速评估：\n",
        "- **单核** 吞吐（单位时间完成的工作量）\n",
        "- **满核** 吞吐（使用所有可用逻辑核心）\n",
        "\n",
        "**特点**：\n",
        "- 无需下载大型模型或数据；\n",
        "- 仅依赖 Python 标准库（可选地检测到 NumPy 时运行一个小型 GEMM 测试）；\n",
        "- 采用可跨设备比较的统一度量：**哈希/秒 (SHA256-H/s)**，并给出 **加速比**。\n",
        "\n",
        "> 备注：此测试以 SHA-256 的多次计算为“工作单元（WU）”；1 WU = 对 512 字节的消息执行 1 次 SHA-256。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# English comments are used in code blocks for portability and clarity.\n",
        "\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import hashlib\n",
        "import statistics\n",
        "import multiprocessing as mp\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "def cpu_info():\n",
        "    \"\"\"Return basic CPU info without external dependencies.\"\"\"\n",
        "    info = {}\n",
        "    info[\"logical_cores\"] = os.cpu_count() or 1\n",
        "    # Try to infer physical cores via /proc/cpuinfo (Linux), fallback to logical.\n",
        "    physical = None\n",
        "    try:\n",
        "        sockets = set()\n",
        "        cores = set()\n",
        "        with open(\"/proc/cpuinfo\", \"r\") as f:\n",
        "            phys_id, core_id = None, None\n",
        "            for line in f:\n",
        "                if \":\" not in line: \n",
        "                    continue\n",
        "                k, v = [s.strip() for s in line.split(\":\", 1)]\n",
        "                if k == \"physical id\":\n",
        "                    phys_id = v\n",
        "                elif k == \"core id\":\n",
        "                    core_id = v\n",
        "                if phys_id is not None and core_id is not None:\n",
        "                    cores.add((phys_id, core_id))\n",
        "        if cores:\n",
        "            physical = len(cores)\n",
        "    except Exception:\n",
        "        pass\n",
        "    info[\"physical_cores_est\"] = physical or info[\"logical_cores\"]\n",
        "    return info\n",
        "\n",
        "def make_block(seed: int, size: int = 512) -> bytearray:\n",
        "    \"\"\"Create a deterministic message buffer of `size` bytes based on a seed.\"\"\"\n",
        "    buf = bytearray(size)\n",
        "    x = seed & 0xFF\n",
        "    for i in range(size):\n",
        "        # Simple LCG-like pattern to avoid trivial optimization; deterministic\n",
        "        x = (x * 131 + 17) & 0xFF\n",
        "        buf[i] = x\n",
        "    return buf\n",
        "\n",
        "def sha256_work(iterations: int, seed: int = 1234) -> Tuple[bytes, int]:\n",
        "    \"\"\"\n",
        "    Perform `iterations` SHA-256 hashes on a 512B buffer, mutating one byte per iter.\n",
        "    Returns (final_digest, iterations).\n",
        "    \"\"\"\n",
        "    buf = make_block(seed, 512)\n",
        "    m = memoryview(buf)\n",
        "    h = hashlib.sha256()\n",
        "    # Use local variables for speed\n",
        "    mv0_index = 0\n",
        "    for i in range(iterations):\n",
        "        # mutate one byte to avoid identical-message fast paths\n",
        "        buf[mv0_index] ^= (i & 0xFF)\n",
        "        h.update(m)  # feed 512 B\n",
        "        # rotate which byte we flip next\n",
        "        mv0_index = (mv0_index + 1) & 511\n",
        "    return h.digest(), iterations\n",
        "\n",
        "def time_single_core(target_seconds: float = 8.0) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Auto-calibrate iterations to run ~target_seconds on 1 core.\n",
        "    Returns dict with throughput in hashes/sec and elapsed time.\n",
        "    \"\"\"\n",
        "    # Quick warmup\n",
        "    _ = sha256_work(1000, seed=1)\n",
        "    # Calibrate\n",
        "    iters = 5000\n",
        "    # Grow until ~0.5s to get stable measurement\n",
        "    while True:\n",
        "        t0 = time.perf_counter()\n",
        "        _ = sha256_work(iters, seed=7)\n",
        "        t1 = time.perf_counter()\n",
        "        dt = t1 - t0\n",
        "        if dt >= 0.5 or iters > 10_000_000:\n",
        "            break\n",
        "        # Scale to approach target_seconds\n",
        "        scale = max(2.0, min(10.0, target_seconds / max(0.1, dt)))\n",
        "        iters = int(iters * scale)\n",
        "        iters = max(iters, 1000)\n",
        "    # Now run 3 repeats and take median\n",
        "    repeats = []\n",
        "    for s in (11, 13, 17):\n",
        "        t0 = time.perf_counter()\n",
        "        _ = sha256_work(iters, seed=s)\n",
        "        t1 = time.perf_counter()\n",
        "        repeats.append(t1 - t0)\n",
        "    median_dt = statistics.median(repeats)\n",
        "    hps = iters / median_dt\n",
        "    return {\"iterations\": float(iters), \"elapsed_sec\": float(median_dt), \"throughput_hps\": float(hps)}\n",
        "\n",
        "def _worker(args):\n",
        "    iters, seed = args\n",
        "    d, n = sha256_work(iters, seed)\n",
        "    return n\n",
        "\n",
        "def time_full_cores(single_core_iters: int, target_seconds: float = 8.0) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Use multiprocessing to saturate all logical cores.\n",
        "    We distribute work so total time is around target_seconds.\n",
        "    \"\"\"\n",
        "    workers = os.cpu_count() or 1\n",
        "    # Roughly adjust iterations per worker based on single-core timing\n",
        "    # We expect full parallel speedup close to workers, so keep same iters per worker.\n",
        "    per_worker_iters = int(single_core_iters)\n",
        "    # Small warmup pool\n",
        "    with mp.Pool(processes=workers) as pool:\n",
        "        _ = list(pool.imap_unordered(_worker, [(2000, i+1) for i in range(min(workers, 4))]))\n",
        "    # Timed run\n",
        "    args = [(per_worker_iters, i+1) for i in range(workers)]\n",
        "    t0 = time.perf_counter()\n",
        "    with mp.Pool(processes=workers) as pool:\n",
        "        done = list(pool.imap_unordered(_worker, args))\n",
        "    t1 = time.perf_counter()\n",
        "    total_iters = sum(done)\n",
        "    dt = t1 - t0\n",
        "    hps = total_iters / dt\n",
        "    return {\n",
        "        \"workers\": workers,\n",
        "        \"iterations_total\": float(total_iters),\n",
        "        \"elapsed_sec\": float(dt),\n",
        "        \"throughput_hps\": float(hps),\n",
        "    }\n",
        "\n",
        "def format_hps(hps: float) -> str:\n",
        "    if hps >= 1e9:\n",
        "        return f\"{hps/1e9:.2f} GH/s\"\n",
        "    if hps >= 1e6:\n",
        "        return f\"{hps/1e6:.2f} MH/s\"\n",
        "    if hps >= 1e3:\n",
        "        return f\"{hps/1e3:.2f} kH/s\"\n",
        "    return f\"{hps:.2f} H/s\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Single-core benchmark ---\n",
        "info = cpu_info()\n",
        "print(\"CPU logical cores:\", info[\"logical_cores\"], \"| physical cores (est):\", info[\"physical_cores_est\"])\n",
        "\n",
        "single = time_single_core(target_seconds=8.0)\n",
        "print(\"\\n[Single-core]\")\n",
        "print(\"Iterations:\", int(single[\"iterations\"]))\n",
        "print(\"Elapsed:    %.3f s\" % single[\"elapsed_sec\"])\n",
        "print(\"Throughput: %s\" % format_hps(single[\"throughput_hps\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Full-cores benchmark ---\n",
        "full = time_full_cores(int(single[\"iterations\"]), target_seconds=8.0)\n",
        "print(\"\\n[Full-cores]\")\n",
        "print(\"Workers:\", full[\"workers\"])\n",
        "print(\"Total iterations:\", int(full[\"iterations_total\"]))\n",
        "print(\"Elapsed:         %.3f s\" % full[\"elapsed_sec\"])\n",
        "print(\"Throughput:      %s\" % format_hps(full[\"throughput_hps\"]))\n",
        "\n",
        "speedup = full[\"throughput_hps\"] / single[\"throughput_hps\"]\n",
        "print(\"\\n[Speedup] Full / Single = %.2f x\" % speedup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Optional: NumPy GEMM test (if numpy is installed) ---\n",
        "try:\n",
        "    import numpy as np\n",
        "    # Control BLAS threads via env vars if user set them before starting the kernel.\n",
        "    # Smallish GEMM to avoid memory pressure\n",
        "    n = 1024\n",
        "    print(f\"\\n[NumPy GEMM] running {n}x{n} matmul once...\")\n",
        "    A = np.random.RandomState(0).randn(n, n).astype(np.float32)\n",
        "    B = np.random.RandomState(1).randn(n, n).astype(np.float32)\n",
        "    t0 = time.perf_counter()\n",
        "    C = A @ B\n",
        "    t1 = time.perf_counter()\n",
        "    flops = 2.0 * n * n * n  # 2*n^3 FLOPs for GEMM\n",
        "    gflops = flops / (t1 - t0) / 1e9\n",
        "    print(\"Elapsed: %.3f s | Approx: %.2f GFLOP/s\" % (t1 - t0, gflops))\n",
        "except Exception as e:\n",
        "    print(\"[NumPy GEMM] NumPy not available or failed:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Summary and persist ---\n",
        "from datetime import datetime\n",
        "report = {\n",
        "    \"timestamp_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
        "    \"cpu\": cpu_info(),\n",
        "    \"single_core\": single,\n",
        "    \"full_cores\": full,\n",
        "    \"speedup_full_over_single\": full[\"throughput_hps\"] / single[\"throughput_hps\"],\n",
        "}\n",
        "\n",
        "import json, os\n",
        "os.makedirs(\"benchmark_reports\", exist_ok=True)\n",
        "with open(\"benchmark_reports/cpu_benchmark_report.json\", \"w\") as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved JSON report to benchmark_reports/cpu_benchmark_report.json\")\n",
        "print(json.dumps(report, indent=2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}